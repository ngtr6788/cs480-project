{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -Uq lightgbm fastai timm xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Turn this to true if you want to train the models given as well as getting\n",
    "# fresh new validation and testing predictions. Otherwise, set this to False\n",
    "# when you already have presaved model files and predictions.\n",
    "fine_tune = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training / Validation / Test Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "competition_path = Path('../input/cs-480-2024-spring/data')\n",
    "\n",
    "original_training_df = pd.read_csv(competition_path / 'train.csv')\n",
    "original_testing_df = pd.read_csv(competition_path / 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_df_presplit = original_training_df.copy()\n",
    "training_df_presplit.id = original_training_df.id.map(lambda x: competition_path / 'train_images' / f\"{str(x)}.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testing_df = original_testing_df.copy()\n",
    "testing_df.id = original_testing_df.id.map(lambda x: competition_path / 'test_images' / f\"{str(x)}.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_df, validation_df = train_test_split(training_df_presplit, random_state=20877679, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_col = \"id\"\n",
    "y_columns = ['X4', 'X11', 'X18', 'X26', 'X50', 'X3112']\n",
    "y_columns_mean = [y_column + '_mean' for y_column in y_columns]\n",
    "x_columns = [col for col in list(testing_df.columns) if col != id_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_X_df = validation_df[x_columns]\n",
    "validation_Y_df = validation_df[y_columns_mean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testing_X_df = testing_df[x_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LightGBM Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(training_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_X_df_lgb, train_Y_df_lgb = train_df[x_columns], train_df[y_columns_mean]\n",
    "valid_X_df_lgb, valid_Y_df_lgb = valid_df[x_columns], valid_df[y_columns_mean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgb_train_datasets = {}\n",
    "lgb_valid_datasets = {}\n",
    "\n",
    "for y_column in y_columns_mean:\n",
    "    lgb_train_datasets[y_column] = lgb.Dataset(train_X_df_lgb, label=train_Y_df_lgb[y_column])\n",
    "    lgb_valid_datasets[y_column] = lgb.Dataset(valid_X_df_lgb, label=valid_Y_df_lgb[y_column], reference=lgb_train_datasets[y_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def r2_score_eval(y_pred, data):\n",
    "    y_true = data.get_label()\n",
    "    return 'r2_score', r2_score(y_true, y_pred), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'mse',\n",
    "    \"metric\": \"None\",\n",
    "    \"verbosity\": 0,\n",
    "    # \"device_type\": \"gpu\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 64,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgb_boosters = {}\n",
    "\n",
    "for y_column in y_columns_mean:\n",
    "    lgb_boosters[y_column] = lgb.train(\n",
    "        params,\n",
    "        train_set=lgb_train_datasets[y_column],\n",
    "        valid_sets=lgb_valid_datasets[y_column],\n",
    "        feval=r2_score_eval,\n",
    "        num_boost_round=1000,\n",
    "        callbacks=[lgb.log_evaluation(period=20), lgb.early_stopping(stopping_rounds=10)],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_lgb(df):\n",
    "    preds_array = []\n",
    "    for y_column in y_columns_mean:\n",
    "        preds = lgb_boosters[y_column].predict(df)\n",
    "        preds_array.append(preds)\n",
    "    preds_tensor = np.array(preds_array).T\n",
    "    \n",
    "    return preds_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_preds_lgb = predict_lgb(validation_X_df)\n",
    "validation_actual = validation_Y_df.values\n",
    "\n",
    "r2_score(validation_actual, validation_preds_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_preds_lgb = predict_lgb(testing_X_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df_xgb, valid_df_xgb = train_test_split(training_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_X_df_xgb, train_Y_df_xgb = train_df_xgb[x_columns], train_df_xgb[y_columns_mean]\n",
    "valid_X_df_xgb, valid_Y_df_xgb = valid_df_xgb[x_columns], valid_df_xgb[y_columns_mean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_train_datasets = {}\n",
    "xgb_valid_datasets = {}\n",
    "\n",
    "for y_column in y_columns_mean:\n",
    "    xgb_train_datasets[y_column] = xgb.DMatrix(train_X_df_xgb, label=train_Y_df_xgb[y_column])\n",
    "    xgb_valid_datasets[y_column] = xgb.DMatrix(valid_X_df_xgb, label=valid_Y_df_xgb[y_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def r2_score_xgb(y_pred, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    return \"r2_score\", r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "common_params = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    # \"device\": \"cuda\",\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"verbosity\": 0,\n",
    "    \"max_depth\": 4,\n",
    "    \"eta\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_boosters = {}\n",
    "\n",
    "for y_column in y_columns_mean:\n",
    "    print(y_column)\n",
    "    xgb_boosters[y_column] = xgb.train(\n",
    "        common_params,\n",
    "        xgb_train_datasets[y_column],\n",
    "        num_boost_round=1000,\n",
    "        evals=[(xgb_valid_datasets[y_column], \"valid\")],\n",
    "        maximize=True,\n",
    "        early_stopping_rounds=30,\n",
    "        custom_metric=r2_score_xgb,\n",
    "        verbose_eval=30,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_xgb(df):\n",
    "    preds_array = []\n",
    "    ddf = xgb.DMatrix(df)\n",
    "    for y_column in y_columns_mean:\n",
    "        preds = xgb_boosters[y_column].predict(ddf)\n",
    "        preds_array.append(preds)\n",
    "    preds_tensor = np.array(preds_array).T\n",
    "    \n",
    "    return preds_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_preds_xgb = predict_xgb(validation_X_df)\n",
    "validation_actual = validation_Y_df.values\n",
    "\n",
    "r2_score(validation_actual, validation_preds_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_preds_xgb = predict_xgb(testing_X_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tabular data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_df_standard = training_df.copy()\n",
    "training_df_minmax = training_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, FunctionTransformer, PowerTransformer, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_standard_scaler = StandardScaler()\n",
    "\n",
    "y_scaled = y_standard_scaler.fit_transform(training_df[y_columns_mean])\n",
    "training_df_standard[y_columns_mean] = y_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_minmax_scaler = MinMaxScaler()\n",
    "\n",
    "y_scaled = y_minmax_scaler.fit_transform(training_df[y_columns_mean])\n",
    "training_df_minmax[y_columns_mean] = y_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastai.metrics import AccumMetric, mse\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score_fastai = AccumMetric(r2_score, to_np=True, invert_arg=True, flatten=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Convolutional Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\"Cleans up the GPU cache for PyTorch as well as starting garbage collection\"\"\"\n",
    "    torch.cuda.empty_cache() # PyTorch thing\n",
    "    gc.collect() # Python thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_augmentations = [\n",
    "    DihedralItem(p=1.0),\n",
    "    Contrast(max_lighting=0.5, p=0.75), # TODO: Pick better max_lighting\n",
    "    Saturation(max_lighting=0.5, p=0.75),\n",
    "    Brightness(max_lighting=0.5, p=0.75),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Notes on PlantVisionLearner: I recommend that fine_tune is first set to True\n",
    "# on the first run because it will create files of presaved models and predictions.\n",
    "# On subsequent runs, you can set fine_tune to False to use the existing models and\n",
    "# predictions, or set to True if you want fresh generated files.\n",
    "\n",
    "class PlantVisionLearner:\n",
    "    def __init__(self, arch_name, scaler, arch_nickname=None, accum=1, resize=None, bs=64, patience=3, \\\n",
    "                 saved_model=False, saved_preds=False, saved_tta=False, model_load=True, opt_func=Adam,):\n",
    "        item_tfms = Resize(resize) if resize is not None else []\n",
    "\n",
    "        self.bs = bs\n",
    "        self.arch_name = arch_name\n",
    "        \n",
    "        if arch_nickname is None:\n",
    "            self.arch_nickname = arch_name\n",
    "        else:\n",
    "            self.arch_nickname = arch_nickname\n",
    "        \n",
    "        if scaler == \"standard\":\n",
    "            self.scaler = y_standard_scaler\n",
    "            df = training_df_standard\n",
    "        elif scaler == \"minmax\":\n",
    "            self.scaler = y_minmax_scaler\n",
    "            df = training_df_minmax\n",
    "        \n",
    "        self.saved_preds = saved_preds\n",
    "        self.saved_tta = saved_tta\n",
    "        \n",
    "        self.saved_model_name = f\"plant_{scaler}_{self.arch_nickname}\"\n",
    "        self.saved_preds_name = f\"preds_{scaler}_{self.arch_nickname}\"\n",
    "        self.saved_tta_name = f\"tta_{scaler}_{self.arch_nickname}\"\n",
    "        \n",
    "        if not model_load:\n",
    "            return\n",
    "        \n",
    "        self.training_images_dls = ImageDataLoaders.from_df(\n",
    "            df, path=\".\",\n",
    "            label_col=y_columns_mean,\n",
    "            y_block=RegressionBlock(len(y_columns_mean)),\n",
    "            item_tfms=item_tfms,\n",
    "            batch_tfms=image_augmentations,\n",
    "            bs=bs // accum\n",
    "        )\n",
    "\n",
    "        cbs = GradientAccumulation(self.bs) if accum > 1 else []    \n",
    "        \n",
    "        self.learner = vision_learner(\n",
    "            self.training_images_dls, arch_name, loss_func=mse,\n",
    "            metrics=r2_score_fastai, n_out=len(y_columns_mean), cbs=cbs,\n",
    "            opt_func=opt_func, model_dir=\".\",\n",
    "        )\n",
    "        \n",
    "        self.fit_cbs = [\n",
    "            EarlyStoppingCallback(monitor='r2_score', comp=np.greater, min_delta=0.0, patience=patience),\n",
    "            SaveModelCallback(monitor='r2_score', comp=np.greater, min_delta=0.0,\n",
    "                with_opt=True, fname=self.saved_model_name\n",
    "            ),\n",
    "        ]\n",
    "        \n",
    "        if saved_model:\n",
    "            load_model(f\"{self.saved_model_name}.pth\", self.learner, self.learner.opt, device=\"cuda:0\")\n",
    "        \n",
    "    def fine_tune(self, *args, **kwargs):\n",
    "        self.learner.fine_tune(*args, **dict(kwargs, cbs=self.fit_cbs))\n",
    "    \n",
    "    def predict(self, df, bs=64):\n",
    "        dl = self.learner.dls.test_dl(df)\n",
    "        preds_scaled, _ = self.learner.get_preds(dl=dl)\n",
    "        preds = self.scaler.inverse_transform(preds_scaled)\n",
    "\n",
    "        return preds\n",
    "    \n",
    "    def tta(self, df, bs=64):\n",
    "        \"TTA = Test Time Augmentation\"\n",
    "        dl = self.learner.dls.test_dl(df)\n",
    "        tta_scaled, _ = self.learner.tta(dl=dl)\n",
    "        tta = self.scaler.inverse_transform(preds_scaled)\n",
    "\n",
    "        return tta\n",
    "    \n",
    "    def get_valid_test_preds(self, save_values=True, bs=64):\n",
    "        if self.saved_preds:\n",
    "            loaded = np.load(f\"{self.saved_preds_name}.npz\")\n",
    "            valid = loaded[\"valid\"]\n",
    "            test = loaded[\"test\"]\n",
    "        else:\n",
    "            valid = self.predict(validation_df, bs)\n",
    "            test = self.predict(testing_df, bs)\n",
    "            \n",
    "            if save_values:\n",
    "                np.savez(self.saved_preds_name,\n",
    "                         valid=valid,\n",
    "                         test=test)\n",
    "        return valid, test\n",
    "    \n",
    "    def get_valid_test_tta(self, save_values=True, bs=64):\n",
    "        if self.saved_tta:\n",
    "            loaded = np.load(f\"{self.saved_tta_name}.npz\")\n",
    "            valid = loaded[\"valid\"]\n",
    "            test = loaded[\"test\"]\n",
    "        else:\n",
    "            valid = self.tta(validation_df, bs=64)\n",
    "            test = self.tta(testing_df, bs=64)\n",
    "            \n",
    "            if save_values:\n",
    "                np.savez(self.saved_tta_name,\n",
    "                         valid=valid,\n",
    "                         test=test)\n",
    "        return valid, test\n",
    "    \n",
    "    def save(self, *args, **kwargs):\n",
    "        self.learner.save(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## convnext_base.fb_in22k_ft_in1k (StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convnext_base_in22k_ft_in1k_standard_vlearner = PlantVisionLearner(\n",
    "    \"convnext_base.fb_in22k_ft_in1k\",\n",
    "    \"standard\",\n",
    "    arch_nickname=\"convnext_base_in22k_ft_in1k\",\n",
    "    model_load=fine_tune,\n",
    "    saved_model=not fine_tune,\n",
    "    saved_preds=not fine_tune,\n",
    "    patience=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if fine_tune:\n",
    "    lr_valley, = convnext_base_in22k_ft_in1k_standard_vlearner.learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if fine_tune:\n",
    "    convnext_base_in22k_ft_in1k_standard_vlearner.fine_tune(18, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_preds_convnext_base_in22k_ft_in1k_standard, test_preds_convnext_base_in22k_ft_in1k_standard = \\\n",
    "    convnext_base_in22k_ft_in1k_standard_vlearner.get_valid_test_preds(save_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r2_score(validation_Y_df.values, validation_preds_convnext_base_in22k_ft_in1k_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## convnext_large_in22k (StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convnext_large_in22k_standard_vlearner = PlantVisionLearner(\n",
    "    \"convnext_large_in22k\",\n",
    "    \"standard\",\n",
    "    model_load=fine_tune,\n",
    "    saved_model=not fine_tune,\n",
    "    saved_preds=not fine_tune,\n",
    "    patience=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if fine_tune:\n",
    "    lr_valley, = convnext_large_in22k_standard_vlearner.learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if fine_tune:\n",
    "    convnext_large_in22k_standard_vlearner.fine_tune(18, lr_valley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_preds_convnext_large_in22k_standard, test_preds_convnext_large_in22k_standard = \\\n",
    "    convnext_large_in22k_standard_vlearner.get_valid_test_preds(save_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r2_score(validation_Y_df, validation_preds_convnext_large_in22k_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## convnext_large_in22k (MinMaxScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convnext_large_in22k_minmax_vlearner = PlantVisionLearner(\n",
    "    \"convnext_large_in22k\",\n",
    "    \"minmax\",\n",
    "    model_load=fine_tune,\n",
    "    saved_model=True,\n",
    "    saved_preds=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if fine_tune:\n",
    "    lr_valley, = convnext_large_in22k_minmax_vlearner.learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine_tune:\n",
    "    convnext_large_in22k_minmax_vlearner.fine_tune(12, lr_valley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_preds_convnext_large_in22k_minmax, test_preds_convnext_large_in22k_minmax = \\\n",
    "    convnext_large_in22k_minmax_vlearner.get_valid_test_preds(save_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r2_score(validation_Y_df, validation_preds_convnext_large_in22k_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## vit_large_patch16_224 (Standard Scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vit_large_patch16_224_standard_vlearner = PlantVisionLearner(\n",
    "    \"vit_large_patch16_224\",\n",
    "    \"standard\",\n",
    "    model_load=fine_tune,\n",
    "    saved_model=not fine_tune,\n",
    "    saved_preds=not fine_tune,\n",
    "    resize=224,\n",
    "    accum=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if fine_tune:\n",
    "    lr_valley, = vit_large_patch16_224_standard_vlearner.learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine_tune:\n",
    "    vit_large_patch16_224_standard_vlearner.fine_tune(12, lr_valley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_preds_vit_large_patch16_224_standard, test_preds_vit_large_patch16_224_standard = \\\n",
    "    vit_large_patch16_224_standard_vlearner.get_valid_test_preds(save_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r2_score(validation_Y_df, validation_preds_vit_large_patch16_224_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## vit_large_patch16_224 (MinMaxScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vit_large_patch16_224_minmax_vlearner = PlantVisionLearner(\n",
    "    \"vit_large_patch16_224\",\n",
    "    \"minmax\",\n",
    "    model_load=fine_tune,\n",
    "    saved_model=not fine_tune,\n",
    "    saved_preds=not fine_tune,\n",
    "    resize=224,\n",
    "    accum=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if fine_tune:\n",
    "    lr_valley, = vit_large_patch16_224_minmax_vlearner.learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine_tune:\n",
    "    vit_large_patch16_224_minmax_vlearner.fine_tune(12, lr_valley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_preds_vit_large_patch16_224_minmax, test_preds_vit_large_patch16_224_minmax = \\\n",
    "    vit_large_patch16_224_minmax_vlearner.get_valid_test_preds(save_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r2_score(validation_Y_df, validation_preds_vit_large_patch16_224_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## convnext_xlarge_in22k (StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convnext_xlarge_in22k_standard_vlearner = PlantVisionLearner(\n",
    "    \"convnext_xlarge_in22k\",\n",
    "    \"standard\",\n",
    "    model_load=fine_tune,\n",
    "    saved_model=not fine_tune,\n",
    "    saved_preds=not fine_tune,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if fine_tune:\n",
    "    lr_valley, = convnext_xlarge_in22k_standard_vlearner.learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine_tune:\n",
    "    convnext_xlarge_in22k_standard_vlearner.fine_tune(12, lr_valley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_preds_convnext_xlarge_in22k_standard, test_preds_convnext_xlarge_in22k_standard = \\\n",
    "    convnext_xlarge_in22k_standard_vlearner.get_valid_test_preds(save_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r2_score(validation_Y_df, validation_preds_convnext_xlarge_in22k_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## convnext_xlarge_in22k (MinMaxScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convnext_xlarge_in22k_minmax_vlearner = PlantVisionLearner(\n",
    "    \"convnext_xlarge_in22k\",\n",
    "    \"minmax\",\n",
    "    model_load=fine_tune,\n",
    "    saved_model=not fine_tune,\n",
    "    saved_preds=not fine_tune,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if fine_tune:\n",
    "    lr_valley, = convnext_xlarge_in22k_minmax_vlearner.learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine_tune:\n",
    "    convnext_xlarge_in22k_minmax_vlearner.fine_tune(12, lr_valley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_preds_convnext_xlarge_in22k_minmax, test_preds_convnext_xlarge_in22k_minmax = \\\n",
    "    convnext_xlarge_in22k_minmax_vlearner.get_valid_test_preds(save_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r2_score(validation_Y_df, validation_preds_convnext_xlarge_in22k_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## mixer_l16_224.goog_in21k (MinMaxScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mixer_l16_224_goog_in21k_minmax_vlearner = PlantVisionLearner(\n",
    "    \"hf_hub:timm/mixer_l16_224.goog_in21k\",\n",
    "    \"minmax\",\n",
    "    arch_nickname=\"mixer_l16_224_goog_in21k\",\n",
    "    resize=224,\n",
    "    model_load=fine_tune,\n",
    "    saved_model=not fine_tune,\n",
    "    saved_preds=not fine_tune,\n",
    "    accum=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if fine_tune:\n",
    "    lr_valley, = mixer_l16_224_goog_in21k_minmax_vlearner.learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine_tune:\n",
    "    mixer_l16_224_goog_in21k_minmax_vlearner.fine_tune(12, lr_valley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_preds_mixer_l16_224_goog_in21k_minmax, test_preds_mixer_l16_224_goog_in21k_minmax = \\\n",
    "    mixer_l16_224_goog_in21k_minmax_vlearner.get_valid_test_preds(save_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r2_score(validation_Y_df, validation_preds_mixer_l16_224_goog_in21k_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## mixer_l16_224.goog_in21k (StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mixer_l16_224_goog_in21k_standard_vlearner = PlantVisionLearner(\n",
    "    \"hf_hub:timm/mixer_l16_224.goog_in21k\",\n",
    "    \"standard\",\n",
    "    arch_nickname=\"mixer_l16_224_goog_in21k\",\n",
    "    resize=224,\n",
    "    model_load=fine_tune,\n",
    "    saved_model=not fine_tune,\n",
    "    saved_preds=not fine_tune,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if fine_tune:\n",
    "    lr_valley, = mixer_l16_224_goog_in21k_standard_vlearner.learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if fine_tune:\n",
    "    mixer_l16_224_goog_in21k_standard_vlearner.fine_tune(12, lr_valley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_preds_mixer_l16_224_goog_in21k_standard, test_preds_mixer_l16_224_goog_in21k_standard = \\\n",
    "    mixer_l16_224_goog_in21k_standard_vlearner.get_valid_test_preds(save_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r2_score(validation_Y_df, validation_preds_mixer_l16_224_goog_in21k_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## And now, average the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_preds = [\n",
    "    validation_preds_lgb,\n",
    "    # validation_preds_xgb,\n",
    "    validation_preds_convnext_base_in22k_ft_in1k_standard,\n",
    "    validation_preds_convnext_large_in22k_standard,\n",
    "    # validation_preds_convnext_large_in22k_minmax,\n",
    "    validation_preds_vit_large_patch16_224_standard,\n",
    "    validation_preds_vit_large_patch16_224_minmax,\n",
    "    validation_preds_convnext_xlarge_in22k_standard,\n",
    "    validation_preds_convnext_xlarge_in22k_minmax,\n",
    "    # validation_preds_mixer_l16_224_goog_in21k_standard,\n",
    "    validation_preds_mixer_l16_224_goog_in21k_minmax,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "validation_preds_colstack = np.column_stack(validation_preds)\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    LinearRegression(),\n",
    "    validation_preds_colstack,\n",
    "    validation_Y_df.values,\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(validation_preds_colstack, validation_Y_df.values)\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "linreg_validation_preds = linear_model.predict(validation_preds_colstack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r2_score(validation_Y_df.values, linreg_validation_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "validation_preds_stack = np.stack(validation_preds, axis=0)\n",
    "\n",
    "def weighted_average_maximize(weights):\n",
    "    weights = np.array(weights)\n",
    "    # weights = weights / np.sum(weights) # Normalize weights\n",
    "\n",
    "    weighted_avg_pred = np.tensordot(weights, validation_preds_stack, axes=(0, 0))\n",
    "\n",
    "    return -r2_score(validation_Y_df.values, weighted_avg_pred)\n",
    "\n",
    "init_weights = np.random.uniform(-4, 4, size=validation_preds_stack.shape[0])\n",
    "# init_weights /= np.sum(init_weights) # Normalize weights\n",
    "\n",
    "result = minimize(\n",
    "    weighted_average_maximize, \n",
    "    init_weights,\n",
    "    # bounds=[(0, 1)] * validation_preds_stack.shape[0] # Normalize weights\n",
    ")\n",
    "\n",
    "weights = result[\"x\"]\n",
    "# weights /= np.sum(weights) # Normalize the weights again.\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weighted_validation_preds = np.tensordot(weights, validation_preds_stack, axes=(0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r2_score(validation_Y_df.values, weighted_validation_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i, col in enumerate(y_columns_mean):\n",
    "    actual_list = list(validation_actual[:,i])\n",
    "    preds_list = list(linreg_validation_preds[:,i])\n",
    "\n",
    "    print(col, r2_score(actual_list, preds_list))\n",
    "    plt.scatter(actual_list, preds_list)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_preds = [\n",
    "    test_preds_lgb,\n",
    "    # test_preds_xgb,\n",
    "    test_preds_convnext_base_in22k_ft_in1k_standard,\n",
    "    test_preds_convnext_large_in22k_standard,\n",
    "    # test_preds_convnext_large_in22k_minmax,\n",
    "    test_preds_vit_large_patch16_224_standard,\n",
    "    test_preds_vit_large_patch16_224_minmax,\n",
    "    test_preds_convnext_xlarge_in22k_standard,\n",
    "    test_preds_convnext_xlarge_in22k_minmax,\n",
    "    # test_preds_mixer_l16_224_goog_in21k_standard,\n",
    "    test_preds_mixer_l16_224_goog_in21k_minmax,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_preds_colstack = np.column_stack(test_preds)\n",
    "\n",
    "test_preds = linear_model.predict(test_preds_colstack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test_id = original_testing_df.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit_df = pd.DataFrame(test_preds, columns=y_columns)\n",
    "submit_df[\"id\"] = X_test_id\n",
    "submit_df = submit_df[[\"id\", *y_columns]]\n",
    "submit_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "submit_df"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8915386,
     "sourceId": 81655,
     "sourceType": "competition"
    },
    {
     "modelId": 99773,
     "modelInstanceId": 75052,
     "sourceId": 89464,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 99853,
     "modelInstanceId": 75132,
     "sourceId": 89567,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 99917,
     "modelInstanceId": 75191,
     "sourceId": 89655,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
